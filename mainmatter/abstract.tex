Somatic mutations of cancerous lesions and their corresponding medical images offer endogenous and exogenous insights into tumor etiology for patient diagnosis and prognosis.  The confluence of mutational and imaging data has led to a new branch of informatics called imaging genomics which correlates the datasets for downstream tasks such as inference or prediction of mutations from a lesion image.  To account for the complexity and high dimensionality of both datasets, many models focus on a subset somatic mutations based on frequency, resulting in the common learning problem of overfitting, which is a cause of underutilizing the full dataset.  Therefore the models typically are only applicable to a small population of patients.  In this thesis, we exploit the pairing of Bayesian nonparametrics and inference networks to create a learning algorithm that translates imaging data into predictions of a patient's somatic mutation profile.

We start by considering the sparse phenomena of somatic mutation datasets, where there are many, few frequently occurring mutations and a long-tail of rare mutations.  Our goal is to decompose the dataset into interpretable features that are also biologically significant.  The standard algorithms of clustering or decomposition, such as Principal Component Analysis (PCA), of the data follows similar methodologies as seen in natural language process, but the same assumptions cannot be applied to biological systems.  A clustering approach assigns a mutation to a single cluster, however, a single mutation is known to belong in multiple distinct biological processes during tumor angiogenesis.  Analysis that decompose the data onto a smaller subspace assume the data is generated through a multinomial likelihood or by penalizing the likelihood using a penalty function such as elastic net for modeling sparsity.  A suitable method for analysis of somatic mutation datasets should explicitly model highly over-dispersed count data along with biological correlations of the mutations.  Through the use of beta-bernoulli stochastic process (BeBP) one can examine an unbounded number of features that are not distinct in the set of mutations.  Our work shows robust learning of interpretable features of somatic mutation datasets with respect to the full mutational profile.  We demonstrate our work on the Pan Cancer Somatic Mutation Dataset, validating the interpretable features by linking them to biologically significance using over-representation analysis.  The underlying features can then be used for understanding the biology of the lesion. 

Before we explore the common subspace of somatic mutations and imaging, we aim to identify local patterns in lesion images for prediction of the histology of breast lesions and patient treatment effect.  Before, the rise of deep neural networks many images relied on hand-crafted features that exploited the texture and shape information available in pixels, however, these features cannot always be applied in medical imaging domain as there is low variance between pixels as in the case of Positron emission tomographyâ€“computed tomography (PET-CT) or they are not based on RGB values like in Diffusion Weighted Magnetic Resonance Imaging (DW-MRI).  Moreover, although a deep learning approach is ideal due to it's data-driven nature, the need for a large dataset limits it's use in some medical domains.  Our work studies imaging features from two different imaging modalities to determine the influence of imaging features on prediction scores.  For DW-MRI we study histogram features based on the parameter maps generated from two exponential functions, Continuous Time Random Walk (CTRW) and Intravoxel Incoherent Motion (IVIM), generated from high \textit{b}-values and low \textit{b}-values respectively.  We show that a combination of features from different parameter maps is superior to modeling the underlying lesion histology.  We then show the value of modeling a lesion in the 3D space as the prediction of treatment response is influenced by the intra-heterogenity of a lesion and as such a volumetric representation offers a comprehensive profile of the lesion.  Though 2D lesion images are the most common when performing prediction tasks for malignancy, 3D representation offer a richer image feature set to exploit for complex prediction tasks

The central topic of our thesis is the correspondence between somatic mutations and medical image of lesions.  We build upon our previous work to help solve two issues in creating this model: the exact location of the lesion biopsy is unknown therefore we create a volumetric representation of the lesion, and the ability to account for the sparse and high dimensional nature of somatic mutation datasets.  To account for increasing modeling complexity we rely on the inference network of variational autoencoders (VAE).  Of course, as mentioned to full utilize VAEs, a larger dataset is needed, as such we build a pan cancer dataset of 1063 samples that compromises of point cloud representations of lesions and their corresponding somatic mutations.  This dataset is a specific subset of the already amazing work done in the collections of data from The Cancer Genomic Archive (TCGA) and The Cancer Imaging Archive (TCIA).  We demonstrate our model on this subset of data for predicting a patient's full somatic mutation profile on just the lesion images.    